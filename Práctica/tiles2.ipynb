{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entorno jugable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "\n",
    "# Configuración de pantalla de juego\n",
    "width, height = 400, 600\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "\n",
    "# Colores\n",
    "white = (255, 255, 255)\n",
    "black = (0, 0, 0)\n",
    "\n",
    "# Jugador\n",
    "player_size = 50\n",
    "player_x = width // 2 - player_size // 2\n",
    "player_y = height - 2 * player_size\n",
    "\n",
    "# Obstáculos\n",
    "obstacle_size = 50\n",
    "obstacle_speed = 5\n",
    "obstacle_frequency = 25  # A mayor valor, menos obstáculos\n",
    "obstacles = []\n",
    "\n",
    "# Reloj para controlar la velocidad del juego\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Función para mostrar un mensaje en la pantalla\n",
    "def show_message(message, size, color, y_offset):\n",
    "    font = pygame.font.Font(None, size)\n",
    "    text = font.render(message, True, color)\n",
    "    text_rect = text.get_rect(center=(width // 2, height // 2 + y_offset))\n",
    "    screen.blit(text, text_rect)\n",
    "\n",
    "# Bucle principal del juego\n",
    "running = True\n",
    "waiting_for_restart = False\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    keys = pygame.key.get_pressed()\n",
    "    player_speed = 5\n",
    "    player_x -= keys[pygame.K_LEFT] * player_speed\n",
    "    player_x += keys[pygame.K_RIGHT] * player_speed\n",
    "\n",
    "    # Límites del jugador\n",
    "    player_x = max(0, min(player_x, width - player_size))\n",
    "\n",
    "    # Generar obstáculos aleatorios\n",
    "    if random.randint(0, obstacle_frequency) == 0:\n",
    "        obstacle_x = random.randint(0, width - obstacle_size)\n",
    "        obstacle_y = 0\n",
    "        obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    # Mover y dibujar obstáculos\n",
    "    new_obstacles = []\n",
    "    for obstacle in obstacles:\n",
    "        obstacle_x, obstacle_y = obstacle\n",
    "        obstacle_y += obstacle_speed\n",
    "        pygame.draw.rect(screen, white, (obstacle_x, obstacle_y, obstacle_size, obstacle_size))\n",
    "        if obstacle_y < height:\n",
    "            new_obstacles.append((obstacle_x, obstacle_y))\n",
    "    obstacles = new_obstacles\n",
    "\n",
    "    # Dibujar jugador\n",
    "    pygame.draw.rect(screen, white, (player_x, player_y, player_size, player_size))\n",
    "\n",
    "    # Verificar colisiones\n",
    "    player_rect = pygame.Rect(player_x, player_y, player_size, player_size)\n",
    "    for obstacle in obstacles:\n",
    "        obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], obstacle_size, obstacle_size)\n",
    "        if player_rect.colliderect(obstacle_rect):\n",
    "            show_message(\"Game Over\", 36, white, -20)\n",
    "            show_message(\"Press 'R' to Restart\", 24, white, 20)\n",
    "            pygame.display.flip()\n",
    "            waiting_for_restart = True\n",
    "\n",
    "    pygame.display.flip()\n",
    "    screen.fill(black)\n",
    "    clock.tick(30)\n",
    "\n",
    "    # Bucle para esperar la pulsación de la tecla 'R' para reiniciar el juego\n",
    "    while waiting_for_restart:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "                waiting_for_restart = False\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_r:\n",
    "                    waiting_for_restart = False\n",
    "\n",
    "        # Muestra el mensaje de reinicio en la pantalla\n",
    "        show_message(\"Press 'R' to Restart\", 24, white, 20)\n",
    "        pygame.display.flip()\n",
    "        clock.tick(30)\n",
    "\n",
    "        # Limpiar y reiniciar el juego\n",
    "        player_x = width // 2 - player_size // 2\n",
    "        player_y = height - 2 * player_size\n",
    "        obstacles = []\n",
    "\n",
    "pygame.quit()\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaración de Entorno de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        # Configuración de pantalla de juego\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "\n",
    "        # Colores\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        # Jugador\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        # Obstáculos\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25  # A mayor valor, menos obstáculos\n",
    "        self.obstacles = []\n",
    "\n",
    "        # Reloj para controlar la velocidad del juego\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Definir el espacio de observación y de acción\n",
    "        self.observation_space = spaces.Discrete(2)  # Ajusta el espacio de observación según tu juego\n",
    "        self.action_space = spaces.Discrete(2)  # Ajusta el espacio de acción según tu juego\n",
    "\n",
    "        # Define recompensas y penalizaciones\n",
    "        self.reward_for_movement = 0.1\n",
    "        self.reward_for_avoiding_obstacle = 1.0\n",
    "        self.penalty_for_collision = -10\n",
    "\n",
    "        # Define parámetros de exploración vs. explotación\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def reset(self):\n",
    "        # Reiniciar el juego y devolver el estado inicial\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Realizar la acción en el juego y devolver la observación, la recompensa y si el episodio ha terminado\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        # Verificar colisiones\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            done = False\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        # Mostrar el estado actual del juego\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        # Cerrar el entorno\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Devuelve la observación actual (podría ser más compleja según tu juego)\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        # Manejar el movimiento del jugador según la acción\n",
    "        player_speed = 5\n",
    "        self.player_x += (2 * action - 1) * player_speed  # Mover a la izquierda si action es 0, mover a la derecha si action es 1\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        # Generar obstáculos aleatorios\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        # Mover y dibujar obstáculos\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        # Dibujar jugador\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        # Verificar colisiones entre el jugador y los obstáculos\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True  # Colisión detectada\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izquierda Compulsiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleGameEnv()\n",
    "num_episodes = 1000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    observation = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        # Exploración vs. Explotación\n",
    "        if random.uniform(0, 1) < env.epsilon:\n",
    "            action = env.action_space.sample()  # Explorar: seleccionar una acción al azar\n",
    "        else:\n",
    "            # Explotar: seleccionar la mejor acción según la política actual\n",
    "            # (aquí usarías tu modelo de aprendizaje por refuerzo)\n",
    "            action = 0  # Ajusta el valor según tu lógica\n",
    "\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleGameEnv()\n",
    "num_episodes = 1000\n",
    "\n",
    "# Inicializar la tabla Q con valores arbitrarios\n",
    "Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "# Hiperparámetros de Q-learning\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "exploration_prob = 0.1\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        # Elegir la acción según la política epsilon-greedy\n",
    "        if np.random.rand() < exploration_prob:\n",
    "            action = env.action_space.sample()  # Explorar: seleccionar una acción al azar\n",
    "        else:\n",
    "            action = np.argmax(Q_table[state, :])  # Explotar: seleccionar la mejor acción según la política actual\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Actualizar la tabla Q\n",
    "        best_next_action = np.argmax(Q_table[next_state, :])\n",
    "        Q_table[state, action] += learning_rate * (reward + discount_factor * Q_table[next_state, best_next_action] - Q_table[state, action])\n",
    "\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No sé qué le pasa a este, no funciona del todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        # Configuración de pantalla de juego\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "\n",
    "        # Colores\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        # Jugador\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        # Obstáculos\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25  # A mayor valor, menos obstáculos\n",
    "        self.obstacles = []\n",
    "\n",
    "        # Reloj para controlar la velocidad del juego\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Definir el espacio de observación y de acción\n",
    "        self.observation_space = spaces.Discrete(2)  # Ajusta el espacio de observación según tu juego\n",
    "        self.action_space = spaces.Discrete(2)  # Ajusta el espacio de acción según tu juego\n",
    "\n",
    "        # Define recompensas y penalizaciones\n",
    "        self.reward_for_movement = 0.1\n",
    "        self.penalty_for_collision = -10\n",
    "        self.reward_for_obstacle_avoidance = 1  # Nueva recompensa por obstáculo evitado\n",
    "\n",
    "        # Define parámetros de exploración vs. explotación\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def reset(self):\n",
    "        # Reiniciar el juego y devolver el estado inicial\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Realizar la acción en el juego y devolver la observación, la recompensa y si el episodio ha terminado\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        # Verificar colisiones\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            # Recompensa adicional por obstáculo evitado\n",
    "            reward += self._check_obstacle_avoidance_reward()\n",
    "            done = False\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        # Mostrar el estado actual del juego\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        # Cerrar el entorno\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Devuelve la observación actual (podría ser más compleja según tu juego)\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        # Manejar el movimiento del jugador según la acción\n",
    "        player_speed = 5\n",
    "        self.player_x += (2 * action - 1) * player_speed  # Mover a la izquierda si action es 0, mover a la derecha si action es 1\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        # Generar obstáculos aleatorios\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        # Mover y dibujar obstáculos\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        # Dibujar jugador\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        # Verificar colisiones entre el jugador y los obstáculos\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True  # Colisión detectada\n",
    "        return False\n",
    "\n",
    "    def _check_obstacle_avoidance_reward(self):\n",
    "    # Verificar si hay obstáculos presentes\n",
    "        if not self.obstacles:\n",
    "            return 0\n",
    "\n",
    "        # Verificar si el jugador está cerca de un obstáculo\n",
    "        min_distance_to_obstacle = min(abs(obstacle[0] - self.player_x) for obstacle in self.obstacles)\n",
    "        if min_distance_to_obstacle < self.player_size + self.obstacle_size:\n",
    "            return self.reward_for_obstacle_avoidance\n",
    "        else:\n",
    "            # Incentivar el movimiento hacia la derecha si no hay obstáculos cercanos\n",
    "            return self.reward_for_movement / 2\n",
    "\n",
    "\n",
    "# Ejemplo de uso del entorno\n",
    "env = SimpleGameEnv()\n",
    "num_episodes = 1000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    observation = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        # Exploración vs. Explotación\n",
    "        if random.uniform(0, 1) < env.epsilon:\n",
    "            action = env.action_space.sample()  # Explorar: seleccionar una acción al azar\n",
    "        else:\n",
    "            # Explotar: seleccionar la mejor acción según la política actual\n",
    "            action = 0  # Ajusta el valor según tu lógica\n",
    "\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        observation = next_observation\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con múltiples entrenamientos al mismo tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        # Configuración de pantalla de juego\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "\n",
    "        # Colores\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        # Jugador\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        # Obstáculos\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        # Reloj para controlar la velocidad del juego\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Definir el espacio de observación y de acción\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        # Define recompensas y penalizaciones\n",
    "        self.reward_for_movement = 0.1\n",
    "        self.penalty_for_collision = -10\n",
    "        self.reward_for_obstacle_avoidance = 1  # Nueva recompensa\n",
    "\n",
    "        # Define parámetros de exploración vs. explotación\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        obstacle_avoided = self._check_obstacle_avoidance()  # Nueva verificación\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            if obstacle_avoided:\n",
    "                reward += self.reward_for_obstacle_avoidance  # Nueva recompensa\n",
    "            done = False\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        self.player_x -= action * player_speed\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _check_obstacle_avoidance(self):\n",
    "        if not self.obstacles:\n",
    "            return False\n",
    "\n",
    "        min_distance_to_obstacle = min(abs(obstacle[0] - self.player_x) for obstacle in self.obstacles)\n",
    "        return min_distance_to_obstacle > self.player_size + self.obstacle_size\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        return random.choice([0, 1])\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            if random.uniform(0, 1) < env.epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.select_action(observation)\n",
    "\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explotación > Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        self.reward_for_movement = 0.1\n",
    "        self.penalty_for_collision = -10\n",
    "        self.reward_for_obstacle_avoidance = 1\n",
    "\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        obstacle_avoided = self._check_obstacle_avoidance()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            if obstacle_avoided:\n",
    "                reward += self.reward_for_obstacle_avoidance\n",
    "            done = False\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        self.player_x -= action * player_speed\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _check_obstacle_avoidance(self):\n",
    "        if not self.obstacles:\n",
    "            return False\n",
    "\n",
    "        min_distance_to_obstacle = min(abs(obstacle[0] - self.player_x) for obstacle in self.obstacles)\n",
    "        return min_distance_to_obstacle > self.player_size + self.obstacle_size\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        # Utiliza la política actual para elegir la acción\n",
    "        # (aquí es donde usarías tu modelo de aprendizaje por refuerzo)\n",
    "        action = 1  # Ajusta según la lógica de tu modelo\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otro! Intento más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        self.reward_for_movement = 0.1\n",
    "        self.penalty_for_collision = -10\n",
    "        self.reward_for_obstacle_avoidance = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        obstacle_avoided = self._check_obstacle_avoidance()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            if obstacle_avoided:\n",
    "                reward += self.reward_for_obstacle_avoidance\n",
    "            done = False\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        self.player_x -= action * player_speed\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _check_obstacle_avoidance(self):\n",
    "        if not self.obstacles:\n",
    "            return False\n",
    "\n",
    "        min_distance_to_obstacle = min(abs(obstacle[0] - self.player_x) for obstacle in self.obstacles)\n",
    "        return min_distance_to_obstacle > self.player_size + self.obstacle_size\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        # Modificamos la lógica de selección de acciones para dar más énfasis a la explotación\n",
    "        # (aquí es donde usarías tu modelo de aprendizaje por refuerzo)\n",
    "        action = 1 if random.uniform(0, 1) < self.epsilon else 0\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ojo con este modelito de arriba, no estaba del todo mal, pero terminó el entrenamiento por su cuenta. \n",
    "Como errores: solo se mueve hacia la izquierda, aunque de forma más humana, no de forma compulsiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este parece funcionar bien, pero no aprende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.reward_for_movement = 0.1\n",
    "        self.penalty_for_collision = -10\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            done = False\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:  # Mover hacia la izquierda\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:  # Mover hacia la derecha\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        # Modificamos la lógica de selección de acciones para permitir movimientos hacia la derecha\n",
    "        action = random.choice([0, 1, 2])\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a cambiar las recompensas (mejoría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.reward_for_movement = 0.01\n",
    "        self.penalty_for_collision = -50  # Aumentamos la penalización por colisión\n",
    "        self.reward_for_avoiding_obstacle = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            done = False\n",
    "\n",
    "        # Recompensa adicional por evitar obstáculos\n",
    "        if not collision:\n",
    "            reward += self.reward_for_avoiding_obstacle\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:  # Mover hacia la izquierda\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:  # Mover hacia la derecha\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        action = random.choice([0, 1, 2])\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo ahora va muy bien, pero me da la sensación de que va como ciego por la vida. Vamos a darle contexto de cómo se mueven los obstáculos, para que pueda evitarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(3,), dtype=float)  # Añadimos información sobre los obstáculos\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.reward_for_movement = 0.01\n",
    "        self.penalty_for_collision = -50\n",
    "        self.reward_for_avoiding_obstacle = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            done = False\n",
    "\n",
    "        # Recompensa adicional por evitar obstáculos\n",
    "        if not collision and self.player_y < self.height - 2 * self.player_size:\n",
    "            reward += self.reward_for_avoiding_obstacle\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Añadimos información sobre la posición del jugador y la presencia de obstáculos\n",
    "        player_position = self.player_x / self.width\n",
    "        obstacle_info = [0] * self.width\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_info[int(obstacle_x)] = 1\n",
    "        return [player_position] + obstacle_info\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:  # Mover hacia la izquierda\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:  # Mover hacia la derecha\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        # Modificamos la lógica de selección de acciones para permitir movimientos hacia la derecha\n",
    "        action = random.choice([0, 1, 2])\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 1000\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.width // 10, self.height // 10, 1), dtype=int)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.penalty_for_collision = -50  # Aumentamos la penalización por colisión\n",
    "        self.reward_for_avoiding_obstacle = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = 0  # No hay recompensa por movimiento\n",
    "            done = False\n",
    "\n",
    "        # Recompensa adicional por evitar obstáculos\n",
    "        if not collision:\n",
    "            reward += self.reward_for_avoiding_obstacle\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs = np.zeros((self.width // 10, self.height // 10, 1), dtype=int)\n",
    "\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            x, y = obstacle_x // 10, obstacle_y // 10\n",
    "            if 0 <= x < obs.shape[0] and 0 <= y < obs.shape[1]:\n",
    "                obs[x, y] = 1\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:  # Mover hacia la izquierda\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:  # Mover hacia la derecha\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class YourAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        # Lógica para seleccionar la acción basada en la observación actual\n",
    "        # Puedes implementar un modelo de aprendizaje profundo aquí\n",
    "        action = random.choice([0, 1, 2])\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = YourAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente Filtrado (Y mejorado, supuestamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.width // 10, self.height // 10, 1), dtype=int)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.penalty_for_collision = -50  # Aumentamos la penalización por colisión\n",
    "        self.reward_for_avoiding_obstacle = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = 0  # No hay recompensa por movimiento\n",
    "            done = False\n",
    "\n",
    "        # Recompensa adicional por evitar obstáculos\n",
    "        if not collision:\n",
    "            reward += self.reward_for_avoiding_obstacle\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs = np.zeros((self.width // 10, self.height // 10, 1), dtype=int)\n",
    "\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            x, y = obstacle_x // 10, obstacle_y // 10\n",
    "            if 0 <= x < obs.shape[0] and 0 <= y < obs.shape[1]:\n",
    "                obs[x, y] = 1\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:  # Mover hacia la izquierda\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:  # Mover hacia la derecha\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class ImprovedAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        left_obstacle = observation[0, :, :].any()\n",
    "        center_obstacle = observation[1, :, :].any()\n",
    "        right_obstacle = observation[2, :, :].any()\n",
    "\n",
    "        if left_obstacle and not center_obstacle and not right_obstacle:\n",
    "            action = 0  # Mover hacia la izquierda\n",
    "        elif not left_obstacle and not center_obstacle and right_obstacle:\n",
    "            action = 2  # Mover hacia la derecha\n",
    "        else:\n",
    "            action = 1  # No hacer nada\n",
    "\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        pass\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = ImprovedAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vale... tengo dos preguntas... \n",
    "la primera, el agente es consciente de los obstáculos que aparecen? Lo digo porque a veces tiene la izquierda libre, donde podría evitarlos, pero decide moverse a la derecha. \n",
    "\n",
    "y la segunda... si creamos un \"random state\" para que el juego siempre sea el mismo, mejoraría el aprendizaje del modelo, no? Pero sería injusto, porque el modelo aprendería directamente una única situación (movimientos concretos) y no a generalizar y evitar objetos sea cual sea la situación, no?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segunda pregunta: Random State\n",
    "Introducir un \"random state\" para que el juego siempre sea el mismo puede ser útil en algunos casos, pero tiene sus pros y contras. Como mencionas, esto puede ayudar al modelo a aprender comportamientos específicos en ese entorno particular. Sin embargo, como señalas, también puede llevar a un modelo que está especializado en esa situación específica y no generaliza bien a otros escenarios.\n",
    "\n",
    "Es importante encontrar un equilibrio. Puedes usar un conjunto de datos diverso que incluya diferentes configuraciones del juego para que el modelo aprenda a generalizar. También puedes explorar técnicas como el uso de un conjunto de entrenamiento aleatorio, la introducción de variabilidad en el entorno y la política de exploración del agente para asegurarte de que el modelo no se vuelva demasiado específico.\n",
    "\n",
    "En el aprendizaje por refuerzo, la variedad en los datos de entrenamiento es clave para que el modelo generalice bien y tome decisiones informadas en una variedad de situaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPERACIÓN ARDILLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entorno Fijo (sin aleatoriedad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 160, in train_thread\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 144, in update\n",
      "IndexError: index 1404 is out of bounds for axis 1 with size 3\n",
      "Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 160, in train_thread\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 144, in update\n",
      "IndexError: index 3 is out of bounds for axis 1 with size 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilo Thread-4, Episodio 1, Recompensa total: 75\n",
      "Hilo Thread-1, Episodio 1, Recompensa total: 75\n",
      "Hilo Thread-1, Episodio 2, Recompensa total: 145\n",
      "Hilo Thread-4, Episodio 2, Recompensa total: 218\n",
      "Hilo Thread-1, Episodio 3, Recompensa total: 22\n",
      "Hilo Thread-4, Episodio 3, Recompensa total: 11\n",
      "Hilo Thread-1, Episodio 4, Recompensa total: 11\n",
      "Hilo Thread-1, Episodio 5, Recompensa total: 47\n",
      "Hilo Thread-4, Episodio 4, Recompensa total: 48\n",
      "Hilo Thread-1, Episodio 6, Recompensa total: 150\n",
      "Hilo Thread-4, Episodio 5, Recompensa total: 151\n",
      "Hilo Thread-4, Episodio 6, Recompensa total: 0\n",
      "Hilo Thread-1, Episodio 7, Recompensa total: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 160, in train_thread\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 144, in update\n",
      "IndexError: index 3 is out of bounds for axis 1 with size 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilo Thread-1, Episodio 8, Recompensa total: 80\n",
      "Hilo Thread-1, Episodio 9, Recompensa total: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\ciruz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 160, in train_thread\n",
      "  File \"C:\\Users\\ciruz\\AppData\\Local\\Temp\\ipykernel_14476\\2740944519.py\", line 144, in update\n",
      "IndexError: index 4 is out of bounds for axis 1 with size 3\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.width // 10, self.height // 10, 1), dtype=int)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.penalty_for_collision = -50  # Aumentamos la penalización por colisión\n",
    "        self.reward_for_avoiding_obstacle = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = 0  # No hay recompensa por movimiento\n",
    "            done = False\n",
    "\n",
    "        # Recompensa adicional por evitar obstáculos\n",
    "        if not collision:\n",
    "            reward += self.reward_for_avoiding_obstacle\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs = np.zeros((self.width // 10, self.height // 10, 1), dtype=int)\n",
    "\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            x, y = obstacle_x // 10, obstacle_y // 10\n",
    "            if 0 <= x < obs.shape[0] and 0 <= y < obs.shape[1]:\n",
    "                obs[x, y] = 1\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:  # Mover hacia la izquierda\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:  # Mover hacia la derecha\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self):\n",
    "        self.action_space = 3\n",
    "        self.state_space = 2  # Se asume un espacio de estado bidimensional para este ejemplo\n",
    "        self.learning_rate = 0.1\n",
    "        self.discount_rate = 0.99\n",
    "        self.exploration_prob = 0.3\n",
    "        self.q_table = np.zeros((self.state_space, self.action_space))\n",
    "\n",
    "    def _get_best_action(self, state):\n",
    "        return np.argmax(self.q_table[state, :])\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if random.uniform(0, 1) < self.exploration_prob:\n",
    "            return random.choice(range(self.action_space))\n",
    "        else:\n",
    "            return self._get_best_action(state)\n",
    "\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        if not done:\n",
    "            max_next_q = np.max(self.q_table[next_state, :])\n",
    "            updated_q_value = (1 - self.learning_rate) * self.q_table[state, action] + \\\n",
    "                              self.learning_rate * (reward + self.discount_rate * max_next_q)\n",
    "        else:\n",
    "            updated_q_value = (1 - self.learning_rate) * self.q_table[state, action] + self.learning_rate * reward\n",
    "\n",
    "        self.q_table[state, action] = updated_q_value\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = QLearningAgent()\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RRNN (NOPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "class SimpleGameEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleGameEnv, self).__init__()\n",
    "\n",
    "        self.width, self.height = 400, 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Entorno de Aprendizaje\")\n",
    "        self.white = (255, 255, 255)\n",
    "        self.black = (0, 0, 0)\n",
    "\n",
    "        self.player_size = 50\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "\n",
    "        self.obstacle_size = 50\n",
    "        self.obstacle_speed = 5\n",
    "        self.obstacle_frequency = 25\n",
    "        self.obstacles = []\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.reward_for_movement = 0.01\n",
    "        self.penalty_for_collision = -50\n",
    "        self.reward_for_avoiding_obstacle = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_x = self.width // 2 - self.player_size // 2\n",
    "        self.player_y = self.height - 2 * self.player_size\n",
    "        self.obstacles = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._handle_player_movement(action)\n",
    "        self._generate_obstacles()\n",
    "        self._move_and_draw_obstacles()\n",
    "        self._draw_player()\n",
    "\n",
    "        collision = self._check_collisions()\n",
    "        if collision:\n",
    "            reward = self.penalty_for_collision\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.reward_for_movement\n",
    "            done = False\n",
    "\n",
    "        if not collision:\n",
    "            reward += self.reward_for_avoiding_obstacle\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.screen.fill(self.black)\n",
    "        self.clock.tick(30)\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                sys.exit()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return 0\n",
    "\n",
    "    def _handle_player_movement(self, action):\n",
    "        player_speed = 5\n",
    "        if action == 0:\n",
    "            self.player_x -= player_speed\n",
    "        elif action == 2:\n",
    "            self.player_x += player_speed\n",
    "\n",
    "        self.player_x = max(0, min(self.player_x, self.width - self.player_size))\n",
    "\n",
    "    def _generate_obstacles(self):\n",
    "        if random.randint(0, self.obstacle_frequency) == 0:\n",
    "            obstacle_x = random.randint(0, self.width - self.obstacle_size)\n",
    "            obstacle_y = 0\n",
    "            self.obstacles.append((obstacle_x, obstacle_y))\n",
    "\n",
    "    def _move_and_draw_obstacles(self):\n",
    "        new_obstacles = []\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_x, obstacle_y = obstacle\n",
    "            obstacle_y += self.obstacle_speed\n",
    "            pygame.draw.rect(self.screen, self.white, (obstacle_x, obstacle_y, self.obstacle_size, self.obstacle_size))\n",
    "            if obstacle_y < self.height:\n",
    "                new_obstacles.append((obstacle_x, obstacle_y))\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def _draw_player(self):\n",
    "        pygame.draw.rect(self.screen, self.white, (self.player_x, self.player_y, self.player_size, self.player_size))\n",
    "\n",
    "    def _check_collisions(self):\n",
    "        player_rect = pygame.Rect(self.player_x, self.player_y, self.player_size, self.player_size)\n",
    "        for obstacle in self.obstacles:\n",
    "            obstacle_rect = pygame.Rect(obstacle[0], obstacle[1], self.obstacle_size, self.obstacle_size)\n",
    "            if player_rect.colliderect(obstacle_rect):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=self.observation_space.shape),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(self.action_space.n, activation='linear')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss='mse')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        q_values = self.model.predict(np.expand_dims(observation, axis=0))\n",
    "        action = np.argmax(q_values)\n",
    "        return action\n",
    "\n",
    "    def update(self, observation, action, reward, next_observation, done):\n",
    "        target = reward if done else reward + 0.99 * np.max(self.model.predict(np.expand_dims(next_observation, axis=0)))\n",
    "        target_f = self.model.predict(np.expand_dims(observation, axis=0))\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(np.expand_dims(observation, axis=0), target_f, epochs=1, verbose=0)\n",
    "\n",
    "def train_thread(env, agent, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            action = agent.select_action(observation)\n",
    "            next_observation, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(observation, action, reward, next_observation, done)\n",
    "\n",
    "            observation = next_observation\n",
    "\n",
    "            if done:\n",
    "                print(f\"Hilo {threading.current_thread().name}, Episodio {episode + 1}, Recompensa total: {total_reward}\")\n",
    "                break\n",
    "\n",
    "env = SimpleGameEnv()\n",
    "agent = DQNAgent(env.observation_space, env.action_space)\n",
    "\n",
    "num_threads = 4\n",
    "num_episodes_per_thread = 250\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=train_thread, args=(env, agent, num_episodes_per_thread), name=f\"Thread-{i+1}\")\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
